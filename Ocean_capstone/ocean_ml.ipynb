{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57231c4-1656-4bf5-9852-24834b684712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPESCADATA Fish Acoustics: Some Machine Learning Modelling\\nCreated on Tue Sep 17 08:44:33 2024\\n\\n@author: jmanitz\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PESCADATA Fish Acoustics: Some Machine Learning Modelling\n",
    "Created on Tue Sep 17 08:44:33 2024\n",
    "\n",
    "@author: jmanitz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06779500-666b-4808-a97b-3df3d97b5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "000d3f8a-990f-4218-9fb4-8649ec1394bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species_grp\n",
       "ANC      13763\n",
       "MUN       5184\n",
       "VIN       4567\n",
       "Other     2162\n",
       "JUR       1716\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data; source: https://ihma.org.pe/bitacoras-acusticas/\n",
    "path = \"/Users/navne/OneDrive/Desktop/Jule/Documents/climate_projects/ocean_capstone/acoustics_data_2020.csv\"\n",
    "dt = pd.read_csv(path, skipinitialspace=True, delimiter=\";\", low_memory=False) #dt.columns\n",
    "\n",
    "# Select response \n",
    "dt[\"Species_grp\"] = dt[\"Region_class\"].replace({\"BAG\": \"Other\", \"POT\": \"Other\", \"EU\": \"Other\", \"Unclassified\": \"Other\", \"OTR\": \"Other\", \"BON\": \"Other\", \"MIC\": \"Other\", \"PG\": \"Other\", \"JC\": \"Other\", \"CAM\": \"Other\", \"CAB\": \"Other\"})\n",
    "dt[\"Species_grp\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "221ba1c6-8416-4055-9417-74b658a56b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height_mean</th>\n",
       "      <th>Depth_mean</th>\n",
       "      <th>Sv_mean</th>\n",
       "      <th>Sv_min</th>\n",
       "      <th>Sv_max</th>\n",
       "      <th>Sv_noise</th>\n",
       "      <th>Lon_M</th>\n",
       "      <th>Lat_M</th>\n",
       "      <th>NASC</th>\n",
       "      <th>ABC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>27392.000000</td>\n",
       "      <td>2.739200e+04</td>\n",
       "      <td>2.739200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.611526</td>\n",
       "      <td>34.877970</td>\n",
       "      <td>-160.970967</td>\n",
       "      <td>-167.704261</td>\n",
       "      <td>-151.590879</td>\n",
       "      <td>-980.418479</td>\n",
       "      <td>-77.126439</td>\n",
       "      <td>-13.145123</td>\n",
       "      <td>4.095618e+03</td>\n",
       "      <td>9.502279e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.417622</td>\n",
       "      <td>55.066196</td>\n",
       "      <td>297.059548</td>\n",
       "      <td>294.553784</td>\n",
       "      <td>300.393569</td>\n",
       "      <td>10.650949</td>\n",
       "      <td>1.064746</td>\n",
       "      <td>1.965452</td>\n",
       "      <td>1.042351e+05</td>\n",
       "      <td>2.418366e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.725327</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-1006.124041</td>\n",
       "      <td>-81.505565</td>\n",
       "      <td>-18.251702</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.494609</td>\n",
       "      <td>7.498035</td>\n",
       "      <td>-65.007585</td>\n",
       "      <td>-64.988363</td>\n",
       "      <td>-55.219006</td>\n",
       "      <td>-986.730548</td>\n",
       "      <td>-77.286147</td>\n",
       "      <td>-14.563022</td>\n",
       "      <td>9.705766e+00</td>\n",
       "      <td>2.250000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.787972</td>\n",
       "      <td>12.852724</td>\n",
       "      <td>-56.805446</td>\n",
       "      <td>-64.817348</td>\n",
       "      <td>-47.611876</td>\n",
       "      <td>-980.091839</td>\n",
       "      <td>-77.093634</td>\n",
       "      <td>-13.475160</td>\n",
       "      <td>7.819750e+01</td>\n",
       "      <td>1.815000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.644000</td>\n",
       "      <td>27.789329</td>\n",
       "      <td>-50.498772</td>\n",
       "      <td>-63.641564</td>\n",
       "      <td>-40.971255</td>\n",
       "      <td>-973.618896</td>\n",
       "      <td>-76.520483</td>\n",
       "      <td>-12.079879</td>\n",
       "      <td>3.707061e+02</td>\n",
       "      <td>8.600000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.515127</td>\n",
       "      <td>315.094719</td>\n",
       "      <td>-7.530407</td>\n",
       "      <td>-42.212651</td>\n",
       "      <td>-0.253201</td>\n",
       "      <td>-941.014280</td>\n",
       "      <td>-72.096534</td>\n",
       "      <td>-8.282912</td>\n",
       "      <td>1.662787e+07</td>\n",
       "      <td>3.857846e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Height_mean    Depth_mean       Sv_mean        Sv_min        Sv_max  \\\n",
       "count  27392.000000  27392.000000  27392.000000  27392.000000  27392.000000   \n",
       "mean       1.611526     34.877970   -160.970967   -167.704261   -151.590879   \n",
       "std        2.417622     55.066196    297.059548    294.553784    300.393569   \n",
       "min        0.002306      0.725327   -999.000000   -999.000000   -999.000000   \n",
       "25%        0.494609      7.498035    -65.007585    -64.988363    -55.219006   \n",
       "50%        0.787972     12.852724    -56.805446    -64.817348    -47.611876   \n",
       "75%        1.644000     27.789329    -50.498772    -63.641564    -40.971255   \n",
       "max       43.515127    315.094719     -7.530407    -42.212651     -0.253201   \n",
       "\n",
       "           Sv_noise         Lon_M         Lat_M          NASC           ABC  \n",
       "count  27392.000000  27392.000000  27392.000000  2.739200e+04  2.739200e+04  \n",
       "mean    -980.418479    -77.126439    -13.145123  4.095618e+03  9.502279e-05  \n",
       "std       10.650949      1.064746      1.965452  1.042351e+05  2.418366e-03  \n",
       "min    -1006.124041    -81.505565    -18.251702  0.000000e+00  0.000000e+00  \n",
       "25%     -986.730548    -77.286147    -14.563022  9.705766e+00  2.250000e-07  \n",
       "50%     -980.091839    -77.093634    -13.475160  7.819750e+01  1.815000e-06  \n",
       "75%     -973.618896    -76.520483    -12.079879  3.707061e+02  8.600000e-06  \n",
       "max     -941.014280    -72.096534     -8.282912  1.662787e+07  3.857846e-01  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select relevant feastures\n",
    "features = [\"Species_grp\", \"Height_mean\", \"Depth_mean\", \"Sv_mean\",\"Sv_min\", \"Sv_max\", \"Sv_noise\", \"Lon_M\", \"Lat_M\", \"NASC\", \"ABC\"] #\"Region_class\",\n",
    "dt[features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c51191d-c161-4b4f-af59-5833d1d3b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Basic preprocessing\n",
    "def prep_data(data):\n",
    "    #data.fillna(0, inplace=True)  # Fill missing values\n",
    "    data = pd.get_dummies(data, drop_first=True)  # Encode categorical features\n",
    "    return data\n",
    "\n",
    "dt = prep_data(dt[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02010487-895b-4d96-b6f9-e53538786368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 39359731504.529\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Model Training\n",
    "def train_model(data):\n",
    "    \"\"\"Train a machine learning model.\"\"\"\n",
    "    X = data.drop('NASC', axis=1)  # Features\n",
    "    y = data['NASC']               # Target variable\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Compute the MSE for the test data\n",
    "    mse = mean_squared_error(y_pred, y_test)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, 'nasc_model.pkl')\n",
    "    return model\n",
    "\n",
    "m1 = train_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c20ecf-4eab-43ad-8036-865e193ac3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Inference (Predict Function)\n",
    "def predict_churn(input_data):\n",
    "    \"\"\"Simulate a prediction with the trained model.\"\"\"\n",
    "    # Load the trained model\n",
    "    model = joblib.load('nasc_model.pkl')\n",
    "    \n",
    "    # Convert input to DataFrame (in case it's passed as a dictionary)\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(input_df)\n",
    "    return {'nasc_prediction': int(prediction[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a45eab-1108-4f6c-95fc-feb351cf4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Evaluation (Monitoring and Maintenance)\n",
    "def evaluate_model(data):\n",
    "    \"\"\"Evaluate the model on the entire dataset.\"\"\"\n",
    "    # Load features and target\n",
    "    X = data.drop('nasc', axis=1)\n",
    "    y = data['nasc']\n",
    "    \n",
    "    # Load model and predict\n",
    "    model = joblib.load('nasc_model.pkl')\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Report metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Overall Evaluation Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534faf8e-266f-43ee-a05e-d520a6a93080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Running the Pipeline\n",
    "if __name__ == '__main__':\n",
    "    # Load and preprocess data\n",
    "    data = load_data(dt[features])\n",
    "\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(data)\n",
    "    \n",
    "    # Simulate a prediction\n",
    "    sample_data = {'feature1': 0.5, 'feature2': 1.2, 'feature3': 0}  # Replace with actual feature names and values\n",
    "    prediction_result = predict_churn(sample_data)\n",
    "    print(\"Sample Prediction:\", prediction_result)\n",
    "    \n",
    "    # Evaluate model on full dataset\n",
    "    evaluate_model(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
